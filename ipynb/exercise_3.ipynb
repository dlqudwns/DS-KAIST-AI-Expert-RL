{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"exercise_3.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"mWctic8KP4Xq","colab_type":"text"},"source":["## 환경설정"]},{"cell_type":"code","metadata":{"id":"XYISj0IVOPHg","colab_type":"code","colab":{}},"source":["### 환경설정 ###\n","!rm -rf sample_data\n","!apt-get install -y xvfb python-opengl > /dev/null 2>&1\n","!pip install gym pyvirtualdisplay > /dev/null 2>&1\n","!pip install pyglet==1.3.2\n","!pip install pygame\n","\n","### Animation 관련 추가 패키지 ###\n","!pip install box2d-py mako==1.0.7 JSAnimation imageio\n","\n","### Code 받아오기 ###\n","!git clone https://github.com/secury/DS-KAIST-AI-Expert-RL.git\n","\n","%cd DS-KAIST-AI-Expert-RL/"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A7BgYYDHQDrv","colab_type":"text"},"source":["## Q-Learning"]},{"cell_type":"code","metadata":{"id":"jndP6_c6Ongn","colab_type":"code","colab":{}},"source":["import time\n","\n","import gym\n","import envs\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","from IPython import display as ipythondisplay\n","\n","# Library related to Java Script Animation\n","from matplotlib import animation\n","from JSAnimation import IPython_display\n","\n","from pyvirtualdisplay import Display\n","display = Display(visible=0, size=(400, 300))\n","display.start()\n","\n","\n","np.set_printoptions(precision=3, suppress=True, threshold=10000, linewidth=250)\n","\n","\"\"\" Load environment \"\"\"\n","# env_name = 'MazeSample3x3-v0'\n","# env_name = 'MazeSample5x5-v0'\n","# env_name = 'MazeSample10x10-v0'\n","# env_name = 'MazeRandom10x10-v0'\n","# env_name = 'MazeRandom10x10-plus-v0'\n","# env_name = 'MazeRandom20x20-v0'\n","# env_name = 'MazeRandom20x20-plus-v0'\n","env_name = 'MyCartPole-v0'\n","# env_name = 'MyMountainCar-v0'\n","\n","env = gym.make(env_name)\n","env = env.unwrapped\n","env.T = env.R = None\n","\n","\"\"\"\n","env.S: the number of states (integer)\n","env.A: the number of actions (integer)\n","gamma: discount factor (0 ~ 1)\n","\"\"\"\n","\n","def plot_movie_js(image_array):\n","    dpi = 10.0\n","    xpixels, ypixels = image_array[0].shape[0], image_array[0].shape[1]\n","    fig = plt.figure(figsize=(ypixels/(dpi), xpixels/(dpi)), dpi=dpi)\n","    # fig.suptitle(filename, fontsize=160)\n","    # fig.set_xlabel(filename, fontsize=160)\n","    # fig.xlabel(filename, fontsize=160)\n","    im = plt.figimage(image_array[0])\n","\n","    def animate(i):\n","        im.set_array(image_array[i])\n","        return (im,)\n","    \n","    anim = animation.FuncAnimation(fig, animate, frames=len(image_array))\n","    ipythondisplay.display(IPython_display.display_animation(anim))\n","\n","\n","def epsilon_greedy(Q, s, epsilon=0.1):\n","    if np.random.rand() < epsilon:\n","        return np.random.randint(0, env.A)\n","    else:\n","        return np.argmax(Q[s, :])\n","\n","\n","step_size = 0.2\n","\n","Q = np.zeros((env.S, env.A))\n","epsilon = 1.0\n","epsilon_min = 0.1\n","num_episodes = 1000\n","\n","for episode in range(num_episodes):\n","    state = env.reset()\n","    episode_reward = 0.\n","    render_list = []\n","\n","    if episode % 100 == 0 or episode == num_episodes-1:\n","        print('Episode ' + str(episode) + ':')\n","\n","    for t in range(10000):\n","        action = epsilon_greedy(Q, state, epsilon)\n","        next_state, reward, done, info = env.step(action)\n","\n","        ###################\n","        # TODO:\n","        # Update Q-table\n","        target_Q = 0\n","        Q[state, action] = 0\n","        ###################\n","        \n","        episode_reward += reward\n","\n","        env.draw_policy_evaluation(Q)\n","\n","        if episode % 100 == 0 or episode == num_episodes-1:\n","            # print(\"[epi=%4d,t=%4d] state=%4s / action=%d / reward=%7.4f / next_state=%4s / info=%s / Q[s]=%s\" % (episode, t, state, action, reward, next_state, info, Q[state, :]))\n","            screen = env.render(mode='rgb_array')\n","            render_list.append(screen)\n","\n","        if done:\n","            break\n","        state = next_state\n","\n","    epsilon = np.max([epsilon * 0.99, epsilon_min])\n","\n","    # 100 에피소드 마다 지금까지 학습된 Q-network에 따른 trajectory를 무비클립으로 확인\n","    if episode % 100 == 0 or episode == num_episodes-1:\n","        # 마운틴카 실행시 아래 두 라인을 주석 해제 시켜주시고 세번째 라인을 주석처리 시켜주세요.\n","        # if episode != 0:\n","        #     plot_movie_js(render_list)\n","        plot_movie_js(render_list)\n","        print('[%4d] Episode reward=%.4f / epsilon=%f' % (episode, episode_reward, epsilon))\n","        print()\n","\n","    time.sleep(0.1)\n","\n","# ipythondisplay.clear_output(wait=True)\n","env.close()"],"execution_count":0,"outputs":[]}]}